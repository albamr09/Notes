<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style.css" />
    <title>Redes Neuronales</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <!-- For LaTeX -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>
    <!-- Code Highlight -->
    <link
      rel="Stylesheet"
      type="text/css"
      href="https://albamr09.github.io/atom-one-light.min.css"
    />
  </head>
  <body>
    <a
      href="https://albamr09.github.io/"
      style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      "
      >Index</a
    >
    <hr />
    <div class="content">
<p>
<a href="index.html">Back</a>
</p>

<div id="Redes Neuronales"><h1 id="Redes Neuronales" class="header"><a href="#Redes Neuronales">Redes Neuronales</a></h1></div>

<hr />

<div id="Redes Neuronales-Estructura"><h2 id="Estructura" class="header"><a href="#Redes Neuronales-Estructura">Estructura</a></h2></div>

<p>
Dado un ejemplo \(X\), tal que \(X\) es un vector fila \(1 \times 3\):
</p>

\[%align
x = 
\begin{bmatrix}x_1 &amp; x_2 &amp; x_3\end{bmatrix}
\]

<p>
Tenemos que las entradas a la red neuronal con un capa se introducen como sigue:
</p>

<p>
<img src="./assets/nn_ejemplo.svg" alt="Ejemplo Red Neuronal" style="width:350px;height:200px" />
</p>

<p>
De tal manera que obtenemos una salida \(h_\Theta(x)\), esta función se denomina <span id="Redes Neuronales-Estructura-función de activación"></span><strong id="función de activación">función de activación</strong>
</p>

<p>
Supongamos que utilizamos la función sigmoide (problema de clasificación con dos clases):
</p>

\[%align
h_\Theta(X) = \frac{1}{1+e^{-\Theta^TX}}
\]


<div id="Redes Neuronales-Datos de entrada"><h2 id="Datos de entrada" class="header"><a href="#Redes Neuronales-Datos de entrada">Datos de entrada</a></h2></div>

<ul>
<li>
\(X = (x_{ij})\) una matriz \(n \times m\) donde cada \(x_{ij}\) es la característica \(i\) del ejemplo \(j\), tal que 
\begin{align}
X = 
\begin{bmatrix}
x_{11} &amp; \cdots &amp; x_{1m} \\
\cdots &amp; \ddots &amp; \cdots \\
x_{n1} &amp; \cdots &amp; x_{nm} \\
\end{bmatrix} 
\end{align}

</ul>

<p>
<em>Cada columna es un ejemplo</em>
</p>

<p>
<em>En cada fila están los valores de una característica</em>
</p>

<p>
Para regresión lineal, donde hay una salida por cada ejemplo \(j\):
</p>

<ul>
<li>
\(Y = (y_j)\) es un vector fila \(1\times m\) donde cada \(y_j\) es la salida real para el ejemplo \(j\), tal que:

<li>

\begin{align}
Y = \begin{bmatrix} 
y_{1} &amp; \cdots &amp; y_{m} \\
\end{bmatrix} 
\end{align}

</ul>

<p>
Para regresión logística, donde hay \(c\) salidas por cada ejemplo \(j\) (cada salida es la probabilidad de que el ejemplo sea de la clase \(l\): <a href="Redes Neuronales.html#Redes Neuronales-Propagación-Clasificación múltiple">Clasificación múltiple</a>).
</p>

<ul>
<li>
\(Y = (y_{ij})\) es una matriz \(c\times m\) donde cada \(y_{ij}\) es la salida real para el ejemplo \(j\) y la clase \(i\), es decir es un valor binario que indica si el ejemplo \(j\) pertenece (1) o no (0) a la clase \(i\), tal que:

</ul>

\begin{align}
Y = \begin{bmatrix} 
y_{11} &amp; \cdots &amp; y_{m1} \\
\vdots &amp; \ddots &amp; \vdots \\
y_{c1} &amp; \cdots &amp; y_{mc} \\
\end{bmatrix} 
\end{align}

<div id="Redes Neuronales-Propagación"><h2 id="Propagación" class="header"><a href="#Redes Neuronales-Propagación">Propagación</a></h2></div>

<div id="Redes Neuronales-Propagación-Notación"><h4 id="Notación" class="header"><a href="#Redes Neuronales-Propagación-Notación">Notación</a></h4></div>

<ul>
<li>
\(k\) es el número de capas de la red

<li>
Para cada capa \(j\), asumimos que la capa tiene \(q\) nodos.

<li>
\(a_i^{(j)}\): Nodo \(i\) en la capa \(j\)

<li>
\(\Theta^{(j)}\): Matriz de pesos de la capa \(j\) a la capa \(j+1\)

<li>
La dimensión de cada \(\Theta^{(j)}\) es \(S_{j+1} \times (S_j + 1)\)

<ul>
<li>
\(S_{j+1}\): número de características/nodos en la capa \(j+1\).

<li>
\((S_j + 1)\): número de características en la capa \(j\) más 1 (término independiente en cada capa)

</ul>
</ul>

<div id="Redes Neuronales-Propagación-Funcionamiento"><h4 id="Funcionamiento" class="header"><a href="#Redes Neuronales-Propagación-Funcionamiento">Funcionamiento</a></h4></div>

<p>
Sean \(k\) el número de capas de la red. Para cada capa \(j\), con \(0 \leq j \leq k\), supongamos que la capa tiene \(q\) nodos. Con \(a^0 = X_l\) (donde \(X_l\) es un ejemplo: un vector columna en \(X\)):
</p>

<p>
Primero se calcula el término intermedio \(z^{(j)}\), que es un vector columna \(q \times 1\):
</p>

\begin{align}
z^{(j)} = \Theta^{(j)} \cdot a^{(j-1)}
\end{align}


<p>
Donde, como ya hemos dicho, \(\Theta\) es la matriz \(q \times p\) de pesos de la capa \(j\), siendo \(p\) el número de nodos en la capa \((j-1)\) más uno (el término independiente).
</p>

<p>
A continuación se aplica sobre \(z^{(j)}\) la función de activación, tal que:
</p>


\begin{align}
a^{(j)} = g(z^{(j)})
\end{align}


<p>
Esto se representa gráficamente en la siguiente imagen:
</p>

<p>
<img src="./assets/nn_ejemplo_1.svg" alt="Ejemplo Red Neuronal" style="width:1050px;height:600px" />
</p>

<p>
Cabe destacar que la función de activación de la última capa suele ser distinta al resto. De todas formas, las funciones de activación no tienen por qué ser iguales, nosotros en estes ejemplos hemos utilizado la función sigmoide, pero depende de la aplicación que se le quiera da a la red neuronal.
</p>

<div id="Redes Neuronales-Propagación-Clasificación múltiple"><h3 id="Clasificación múltiple" class="header"><a href="#Redes Neuronales-Propagación-Clasificación múltiple">Clasificación múltiple</a></h3></div>

<p>
Para crear una red neuronal que permita trabajar con \(c\) clases lo que hacemos es hacer que la red neuronal tenga \(c\) nodos en su capa de salida. Esto se ilustra en la siguiente imagen:
</p>

<p>
<img src="./assets/nn_ejemplo_multi.svg" alt="Ejemplo Red Neuronal Clasificación Múltiple" style="width:950px;height:550px" />
</p>

<p>
De tal manera que ahora, cada salida \(y_j\) será un vector columna \(c\times1\), donde existe un valor por cada categoría, al igual que la hipótesis para el ejemplo \(j\), \(h_\Theta(x_j)\), es un vector columna \(c\times1\).
</p>

<p>
Como podemos ver, los valores de \(y_j\) indican claramente a qué clase pertenece el ejemplo \(j\) (clase 3), mientras que la hipótesis \(h_\Theta(x_j)\) ofrece, para cada clase (columna) la probabilidad de que el ejemplo \(j\) pertenezca a esa clase.
<hr />
</p>

<div id="Redes Neuronales-Función de coste"><h2 id="Función de coste" class="header"><a href="#Redes Neuronales-Función de coste">Función de coste</a></h2></div>

<div id="Redes Neuronales-Función de coste-Notación"><h4 id="Notación" class="header"><a href="#Redes Neuronales-Función de coste-Notación">Notación</a></h4></div>

<p>
Como ya hemos visto en función del número de clases la salida tendrá distinta forma:
</p>

<ul>
<li>
<span id="Redes Neuronales-Función de coste-Notación-Clasificación binaria"></span><strong id="Clasificación binaria">Clasificación binaria</strong>: para cada ejemplo \(j\), \(y_j \in \{0, 1\}\), \(h_\Theta(x_j) \in \mathbb{R}\)

<li>
<span id="Redes Neuronales-Función de coste-Notación-Clasificación múltiple"></span><strong id="Clasificación múltiple">Clasificación múltiple</strong>: para cada ejemplo \(j\), \(y \in \mathbb{R}^c\), \(h_\Theta(x_j) \in \mathbb{R}^c\), donde \(c\) es el número de clases

<li>
Sea \(k\) el número de capas y \(S_i\) el número de nodos en la capa \(i\).

<li>
Sea \(Y=(y_{ij})\) una matriz \(c\times m\), donde \(m\) es el número de ejemplos y cada \(y_{j}\) es el vector columna \(c\times1\) de salida para el ejemplo \(j\).

</ul>

<hr />

<p>
Definimos la función de coste como sigue:
</p>

\begin{align}
J(\Theta) = - \frac{1}{m} \left\{ \sum_{j=1}^m \sum_{i=1}^c [y_{ij}\cdot \log(h_\Theta(x_j)_i)] + [(1-y_{ij})\cdot \log(1-(h_\Theta(x_j)_i))]\right\}
\end{align}

<p>
El primer sumatorio que va de 1 a \(m\) se encarga de calcular el coste para cada ejemplo \(j\). Mientras que el segundo sumatorio, que va de 1 a \(c\), se encarga de calcular el coste para cada nodo de salida.
</p>

<p>
Esta función se aplica sobre los \(k\) nodos en la capa de salida. 
</p>

<p>
<a href="Ejemplo Cálculo Función de Coste.html">Ejemplo Cálculo Función de Coste</a>
</p>


<div id="Redes Neuronales-Función de coste-Regularización"><h4 id="Regularización" class="header"><a href="#Redes Neuronales-Función de coste-Regularización">Regularización</a></h4></div>

<p>
Definimos la función de coste introduciendo regularización como sigue:
</p>

\begin{align}
J(\Theta) = - \frac{1}{m} \left\{ \sum_{j=1}^m \sum_{i=1}^c [y_{ij}\cdot \log(h_\Theta(x_j)_i)] + [(1-y_{ij})\cdot \log(1-(h_\Theta(x_j)_i))]\right\} + \frac{\lambda}{2m} \sum_{q=1}^k \sum_{i=1}^{S_q}\sum_{j=1}^{S_{q+1}} (\theta_{ji}^{(q)})^2
\end{align}


<p>
Antes de nada, recordar que \(S_q\) denota el número de nodos en la capa \(q\). Entonces, el primer término de la función es igual que cuando no se aplicaba regularización. Expliquemos el segundo término. La regularización, en este caso, consiste en sumar todos los pesos de la red neuronal, por lo tanto:
</p>

<ol>
<li>
Por cada capa \(q\), con \(1 \leq q \leq k\), sumamos todos los elementos de la matriz de pesos \(\Theta^{q}\), que como sabemos tiene dimensiones \(S_{q+1} \times S_q\) 

<li>
Dada la matriz \(\Theta^{(q)}\)

<ol>
<li>
Recorremos cada columna \(i\), con \(1 \leq i \leq S_q\)

<li>
Recorremos cada elemento \(j\) de la columna \(i\), con \(1 \leq j \leq S_{q+1}\)

<li>
Sumamos al total cada elemento de la matriz \(\Theta^{(j)}_{ji}\)

</ol>
<li>
Una vez se han sumado todas las matrices de pesos obtenemos un escalar, que multiplicamos por \(\frac{\lambda}{2m}\)

</ol>

<div id="Redes Neuronales-Retropropagación"><h2 id="Retropropagación" class="header"><a href="#Redes Neuronales-Retropropagación">Retropropagación</a></h2></div>

<div id="Redes Neuronales-Retropropagación-Notación"><h4 id="Notación" class="header"><a href="#Redes Neuronales-Retropropagación-Notación">Notación</a></h4></div>

<p>
La salida de cada capa \(q\) es una matriz \(S_q \times m\), donde \(S_q\) denota el número de nodos en la capa \(q\) y \(m\) denota el número de ejemplos. 
</p>

<p>
Como vimos en nuestras figuras, donde se presentaban los cálculos sólo para un ejemplo, en cada capa \(q\) podemos mapear la salida de los \(S_q\) nodos a un vector columna \(S_q \times 1\). 
</p>

<p>
Si generalizamos esto a \(m\) ejemplos tenemos que la salida de cada capa es una matriz \(S_q \times m\). Esto se ilustra en la siguiente imagen:
</p>

<p>
<img src="./assets/nn_multi_ejemplos.svg" alt="Red Neuronal con varios ejemplos" style="width:800px;height:600px" />
</p>

<hr />

<p>
Vamos, ahora a explicar cómo se aplica la retropropagación. Lo primero que debemos tener en cuenta es que este proceso se basa en la misma idea de optimización que la <a href="Regresión Lineal.html">Regresión Lineal</a> y la <a href="Regresión Logística.html">Regresión Logística</a>, es decir, lo que queremos hacer es minimizar el coste, \(J(\Theta)\)
</p>

<p>
El problema es que debemos derivar \(\frac{\delta J(\Theta)}{\delta \Theta}\), donde \(\Theta\) ya no es una matriz, si no que es un tensor, es decir tenemos que calcular \(\frac{\delta J(\Theta)}{\delta \theta^{(k)}_{it}}\). Los pasos a seguir para calcular los gradientes (cuánto contribuye cada peso \(\theta\) al error):
</p>

<p>
Sea \(c\) el número de nodos en la última capa, \(\theta_{it}\) el peso \(t\) del nodo \(i\) de la última capa \(k\), \(a_{ij}^{(k)}\) la salida del nodo \(i\) para el ejemplo \(j\) en la capa \(k\):
</p>
<ol>
<li>
Calculamos el gradiente de la última capa \(k\) como: \(\frac{\delta J(\Theta)}{\delta \theta_{it}^{(k)}} = \frac{\delta J(\Theta)}{\delta a_{1j}^{(k)}}\frac{\delta a_{1j}^{(k)}}{\delta \theta_{it}^{(k)}}\)

<li>
Calculamos el gradiente en capas intermedias utilizando la regla de la cadena como: \(\frac{\delta J(\Theta)}{\delta \theta_{it}^{(q)}} = \sum_{i=1}^{S_{(q+1)}} \frac{\delta J(\Theta)}{\delta a_{ij}^{(q+1)}}\frac{\delta a_{ij}^{(q+1)}}{\delta a_{ij}^{(q)}}\frac{\delta a_{ij}^{(q)}}{\delta \theta_{it}^{(q)}}\)

</ol>

<p>
Normalmente en las capas intermedias, \(q\), nos referimos al término \(\frac{\delta J(\Theta)}{\delta a_{ij}^{(q+1)}}\) como \(\Delta^{(q+1)}_{ij}\).
</p>

<hr />

<p>
Por ejemplo, supongamos que tenemos una red con tres capas, entonces \(k=3\), dado un ejemplo \(x\). En este caso tenemos que 
</p>
<ol>
<li>
La derivada en la última capa, para el único vector de pesos \(\theta^{(3)}_1\) que tiene \(n\) elementos (<code>features</code> o características), es: \(\frac{\delta J(\Theta)}{\delta \theta_{1t}^{(3)}}\)

<li>
Como \(J(\Theta) = E^{(3)}(a_1^{(3)}) = E^{(3)}(g(z_1^{(3)})) = E^{(3)}(g(\Theta^{(3)}\cdot a^{(2)}))\), donde denotamos la función que calcula el error entre lo predicho y la salida real como \(E\), y \(g\) es la función de activación.

<li>
Entonces, aplicamos la regla de la cadena para cada elemento \(t\) en el vector de pesos \(\theta_1^{(3)}\): \(\frac{\delta J(\Theta)}{\delta \theta_{1t}^{(3)}} = \frac{\delta J(\Theta)}{\delta a_1^{(3)}}\frac{\delta a_1^{(3)}}{\delta z_1^{(3)}}\frac{\delta z_1^{(3)}}{\delta \theta_{it}^{(3)}}\)

<li>
Si ahora queremos obtener la derivada para uno de los vectores de pesos en la capa \(2\), por ejemplo \(\theta_1^{(2)}\), volvemos a aplicar la regla de la cadena.

<li>
Tenemos ahora que desestructurar la función de coste todavía más:

</ol>

\begin{align}
J(\Theta) = E^{(3)}(a_1^{(3)}) = E^{(3)}(g(z_1^{(3)})) = E^{(3)}(g(\Theta^{(3)}\cdot a^{(2)})) = E^{(3)}(g(\Theta^{(3)}\cdot g(z^{(2)}))) = E^{(3)}(g(\Theta^{(3)}\cdot g(\Theta^{(2)} \cdot a^{(1)})))
\end{align}

<ol>
<li>
Entonces, aplicamos la regla de la cadena para cada elemento \(t\) en el vector de pesos \(\theta_1^{(2)}\): 

</ol>

\begin{align}
\frac{\delta J(\Theta)}{\delta \theta_{1t}^{(2)}} = \frac{\delta J(\Theta)}{\delta a_1^{(3)}}\frac{\delta a_1^{(3)}}{\delta z_1^{(3)}}\frac{\delta z_1^{(3)}}{\delta a_{1}^{(2)}}\frac{\delta a_1^{(2)}}{\delta z_{1}^{(2)}}\frac{\delta z_1^{(2)}}{\delta \theta_{1t}^{(2)}}
\end{align}


<p>
Si, en la última capa hubiese más de un sólo nodo, por ejemplo, si en la última capa hubiese un nodo \(a_1^{(3)}\) y un nodo \(a_2^{(3)}\):
</p>

\begin{align}
J(\Theta) = \frac{1}{2} \left[E^{(3)}(a_1^{(3)}) + E^{(3)}(a_2^{(3)})\right]
\end{align}

<p>
Por lo tanto, la derivada en función a uno de los vectores de peso \(\theta_1^{(3)}\) (de entre los dos que hay) sería la derivada de la suma:
</p>

\begin{align}
\frac{\delta J(\Theta)}{\delta \theta_1^{(3)}} = \frac{1}{2} \left[ \frac{\delta}{\delta \theta_1^{(3)}} E^{(3)}(a_1^{(3)}) + \frac{\delta}{\delta \theta_1^{(3)}} E^{(3)}(a_2^{(3)})\right]
\end{align}

<p>
El procedimiento se ilustra en la siguiente figura:
</p>

<p>
<img src="./assets/backprop.svg" alt="Retropropagación" style="width:1000px;height:600px;" />
</p>

<div id="Redes Neuronales-Retropropagación-Derivada de la función de coste"><h3 id="Derivada de la función de coste" class="header"><a href="#Redes Neuronales-Retropropagación-Derivada de la función de coste">Derivada de la función de coste</a></h3></div>

<p>
A continuación explicamos cómo derivar la función de coste (<span id="Redes Neuronales-Retropropagación-Derivada de la función de coste-Paso 1"></span><strong id="Paso 1">Paso 1</strong>).
</p>

<p>
<a href="Derivada de la función de coste.html">Derivada de la función de coste</a>
</p>


<hr />

<div id="Redes Neuronales-Retropropagación-Capas intermedias"><h3 id="Capas intermedias" class="header"><a href="#Redes Neuronales-Retropropagación-Capas intermedias">Capas intermedias</a></h3></div>

<p>
Veamos, ahora, cómo llevar a cabo el <span id="Redes Neuronales-Retropropagación-Capas intermedias-Paso 2"></span><strong id="Paso 2">Paso 2</strong>: ¿cómo calculamos el gradiente (o lo que contribuye el peso \(it\) en el error) para los pesos de las capas intermedias?, es decir, cómo calculamos:
</p>

\[%align
\frac{\delta J(\Theta)}{\delta \theta_{it}^{(q)}} 
\]

<p>
<a href="Derivadas capas intermedias.html">Derivadas capas intermedias</a>
</p>


<div id="Redes Neuronales-Algoritmo"><h2 id="Algoritmo" class="header"><a href="#Redes Neuronales-Algoritmo">Algoritmo</a></h2></div>
</div>
  </body>
  <script
    type="text/javascript"
    src="https://albamr09.github.io/highlight.min.js"
  ></script>
  <script
    type="text/javascript"
    src="https://albamr09.github.io/zepto.min.js"
  ></script>
  <script type="text/javascript">
    $("pre").each(function (index, item) {
      $(item).html("<code>" + $(item).html() + "</code>");
    });
    hljs.initHighlightingOnLoad();
  </script>
</html>
